'''
Created on Apr 21, 2016

@author: neil
'''
import json
import tweepy
from osgeo import ogr
from config import (ACCESS_TOKEN, ACCESS_TOKEN_SECRET,
                    CONSUMER_KEY, CONSUMER_SECRET)
from config import MAX_SEARCH_TWEETS
from EONet_json import eonet_jason


QUERY_STRING = 'flooding in houston texas'
QUERY_POLYGON = '''{
                    "date": "2016-04-17T00:00:00Z",
                    "type": "Polygon", 
                    "coordinates": [[ [-95.980224609375, 29.213727993972313], [-95.980224609375, 30.36072451862922], [-94.64599609375, 30.36072451862922], [-94.64599609375, 29.213727993972313], [-95.980224609375, 29.213727993972313] ]]
                }'''


class TweetFetcher(object):
    
    consumer = None
    
    __max_tweets = MAX_SEARCH_TWEETS
    
    
    def __init__(self, api):
        self.__api = api
        
    def fetch(self):
        # The consumer has the search string.
        query = self.consumer.query
        
        # Execute the search and page through the results. 
        last_id = -1
        count = 0
        while count < self.__max_tweets:
    
            try:
                new_tweets = self.__api.search(q=query, count=count, max_id=str(last_id - 1))
                if not new_tweets:
                    break
                count += len(new_tweets)
                self.consumer.process(new_tweets)
                
                last_id = new_tweets[-1].id
            except tweepy.TweepError as e:
                # depending on TweepError.code, one may want to retry or wait
                # to keep things simple, we will give up on an error
                print e
                break        


class TweetConsumer(object):
    '''
    Consumes the results of a Twitter search.  To use this class, create a
    subclass and implement the _save() method.
    '''
    __polygon = None
    title_matches = 0
    geo_enabled_matches = 0
    geo_matches = 0
    
    def __filter(self, tweet):
        '''
        Checks for the presence of geodata and if the coordinates are near
        the EONet event.  If yes to both, then ...
        '''
        self.title_matches += 1
        retval = False
        if tweet.coordinates is not None:
            self.geo_enabled_matches += 1
            geojson_point = json.dumps(tweet.coordinates)
            point = ogr.CreateGeometryFromJson(geojson_point)
            retval = point.Within(self.__polygon)
            
        if retval:
            self.geo_matches += 1

        return retval
    
    # The polygon needs to be of type POLYGON.  It's a property of the search
    # that's calculated once, before the search, to avoid making this
    # calculation with every tweet.
    def set_polygon(self, poly):
        '''Sets the polygon to use in the search filter.'''
        self.__polygon = ogr.CreateGeometryFromJson(poly)
        
    def reset_counters(self):
        '''Sets the number of title and geo matches to zero.'''
        self.title_matches = 0
        self.geo_matches = 0
    
    def process(self, tweets):
        '''
        Iterate through the tweets, filtering out the relevant ones and then
        send them to a save method.'''
        for tweet in tweets:
            if self.__filter(tweet):
                self._save(tweet)
        
        
# This class is useful for initial development and detailed debugging.
class RawDump(TweetConsumer):
    '''Dumps the tweet, in raw json, to standard out.'''
    def _save(self, tweets):
        for tweet in tweets:
            print tweet


# This class presents refined output to standard out.  It's useful for
# high-level troubleshooting. 
class PrettyDump(TweetConsumer):
        '''
        Presents the most interesting parts of a tweet in formatted text to
        standard out.
        '''
        def _save(self, tweet):
            msg = tweet.text.encode('utf8', 'replace')
            name = tweet.user.name.encode('utf8', 'replace')
            msg_date = tweet.created_at
            place = tweet.place.name.encode('utf8', 'replace')
            print('[Name: %s][Place: %s][At: %s] %s' %
                  (name, place, msg_date, msg))


def search_tweets():
    
    auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)
    auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)
    
    api = tweepy.API(auth)
    tweetfetcher = TweetFetcher(api)
    consumer = PrettyDump()
    tweetfetcher.consumer = consumer
    
    # Loop through the events in EONet.
    eonet_events = json.loads(eonet_jason)
    print('Processing EONet: %s' % eonet_events['description'])
    for event in eonet_events['events']:
        
        # So we can watch the progress on the console.
        event_id = event['id']
        title = event['title']
        print('Event %s: %s' % (event_id, title))
        
        # The Twitter search is on the title and then the results are filtered
        # against the polygon.
        consumer.query = title
        
        # Only polygons supported.
        for geometry in event['geometries']:
            if 'Polygon' == geometry['type']:
                poly = json.dumps(geometry)
                consumer.set_polygon(poly)
                tweetfetcher.fetch()
            else:
                print('No polygons provided with geometry.')
        
        # Done.
        print('Done.  Tweets matching title: %d.  Tweets matching geometry: %d of %d enabled.' %
              (consumer.title_matches, consumer.geo_matches, consumer.geo_enabled_matches))
        consumer.reset_counters()
                
#    consumer.query = QUERY_STRING
#    consumer.set_polygon(QUERY_POLYGON)
#    tweetfetcher.fetch()
    
